{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "def signature():\n",
    "    display(Markdown(f\"\"\"\n",
    "---\n",
    "### 👨‍💻 *Authored by [Erwin R. Pasia](mailto:erwinpasia@gmail.com)*\n",
    "📅 Date: {datetime.now().strftime(\"%B %d, %Y\")}\n",
    "\n",
    "> *\"Code is poetry. Simplicity is elegance.\"*  \n",
    "---\n",
    "\"\"\"))\n",
    "\n",
    "signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CafeGenius: Intelligent Cafe Assistant Demo\n",
    "#\n",
    "# This notebook demonstrates a conversational AI assistant for a cafe,\n",
    "# using Gemini for language understanding and function calling, and\n",
    "# ChromaDB for RAG-based menu search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. Setup and Installation\n",
    "# ==============================================================================\n",
    "print(\"Installing necessary packages...\")\n",
    "# Use %pip for better integration in Jupyter/Colab\n",
    "# Note: Adjust versions as needed based on compatibility and latest releases\n",
    "# Using versions known to be relatively stable at the time of writing (example)\n",
    "%pip install --upgrade --quiet \"google-generativeai>=0.5.0\" \"google-ai-generativelanguage>=0.6.0\" \"chromadb>=0.5.0\" \"google-api-python-client\" \"google-auth\" \"kaggle\"\n",
    "\n",
    "# (Optional) Uninstall conflicting packages if necessary\n",
    "# %pip uninstall -y qqx jupyterlab kfp\n",
    "\n",
    "print(\"Package installation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "\n",
    "# Google Generative AI\n",
    "import google.generativeai as genai\n",
    "import google.ai.generativelanguage as glm # Updated import for types\n",
    "from google.api_core import retry\n",
    "from google.protobuf import struct_pb2 # For function call responses\n",
    "\n",
    "# ChromaDB\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "# Other Utilities\n",
    "from IPython.display import Markdown, display\n",
    "from kaggle_secrets import UserSecretsClient # Or use python-dotenv for local .env files\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. Logging Configuration\n",
    "# ==============================================================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('cafe_genius')\n",
    "logger.info(\"Logging setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. API Key Configuration\n",
    "# ==============================================================================\n",
    "try:\n",
    "    # Prioritize Kaggle secrets if available\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    logger.info(\"Using GOOGLE_API_KEY from Kaggle secrets.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Could not get API key from Kaggle secrets: {e}. Trying environment variable.\")\n",
    "    # Fall back to environment variable for local development\n",
    "    GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if GOOGLE_API_KEY:\n",
    "        logger.info(\"Using GOOGLE_API_KEY from environment variable.\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    logger.error(\"API key not found. Set GOOGLE_API_KEY Kaggle secret or environment variable.\")\n",
    "    # Optional: Provide instructions or raise error\n",
    "    print(\"ERROR: GOOGLE_API_KEY not found. Please set it as a Kaggle secret or environment variable.\")\n",
    "    # raise ValueError(\"API key not found.\") # Uncomment to halt execution if key is missing\n",
    "else:\n",
    "    # Configure the GenAI client\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    logger.info(\"Google Generative AI client configured.\")\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Using google-generativeai version: {genai.__version__}\")\n",
    "    except AttributeError:\n",
    "        logger.warning(\"Could not determine google-generativeai version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. Gemini Embedding Function for ChromaDB (Retry Logic)\n",
    "# ==============================================================================\n",
    "# Import necessary exception types for retry logic\n",
    "from google.api_core import exceptions as api_core_exceptions\n",
    "from google.api_core import retry\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings # Ensure these are imported\n",
    "from typing import Optional, List # Ensure these are imported\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"Custom embedding function using Gemini API (text-embedding-004)\"\"\"\n",
    "    def __init__(self, api_key: Optional[str] = None, task_type=\"retrieval_document\", model_name=\"models/text-embedding-004\"):\n",
    "        # If api_key is provided, configure a temporary client (useful if global config isn't set yet)\n",
    "        if api_key:\n",
    "             genai.configure(api_key=api_key)\n",
    "        self.task_type = task_type\n",
    "        self.model_name = model_name\n",
    "        logger.info(f\"GeminiEmbeddingFunction initialized with model: {self.model_name}\")\n",
    "\n",
    "    # Retry on common transient API errors and connection issues\n",
    "    @retry.Retry(predicate=retry.if_exception_type(\n",
    "        api_core_exceptions.Aborted,\n",
    "        api_core_exceptions.DeadlineExceeded,\n",
    "        api_core_exceptions.ServiceUnavailable,\n",
    "        api_core_exceptions.InternalServerError,\n",
    "        ConnectionError\n",
    "    ))\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        \"\"\"Embeds a list of documents.\"\"\"\n",
    "        if not input:\n",
    "            return []\n",
    "        # Determine correct task type based on ChromaDB's usage hint if available\n",
    "        # This part might need adjustment based on how ChromaDB passes context\n",
    "        current_task_type = self.task_type # Default unless overridden by context\n",
    "\n",
    "        logger.info(f\"Embedding {len(input)} documents with task type: {current_task_type}\")\n",
    "        try:\n",
    "            # Ensure input is a list of strings\n",
    "            if not isinstance(input, list) or not all(isinstance(doc, str) for doc in input):\n",
    "                raise TypeError(\"Input must be a list of strings (Documents).\")\n",
    "\n",
    "            response = genai.embed_content(\n",
    "                model=self.model_name,\n",
    "                content=input,\n",
    "                task_type=current_task_type # Use determined task type\n",
    "            )\n",
    "            # Ensure embeddings are returned correctly\n",
    "            if 'embedding' in response and isinstance(response['embedding'], list):\n",
    "                 # Check if it's a list of lists or just a list (for single input case, though __call__ expects list)\n",
    "                 embeddings = response['embedding']\n",
    "                 if embeddings and not isinstance(embeddings[0], list):\n",
    "                      # API might return a single list for a single input document\n",
    "                      # The ChromaDB interface likely expects a list of lists\n",
    "                      logger.info(f\"Successfully embedded {len(input)} documents (single list wrapper).\")\n",
    "                      return [embeddings]\n",
    "                 else:\n",
    "                      logger.info(f\"Successfully embedded {len(embeddings)} documents.\")\n",
    "                      return embeddings\n",
    "\n",
    "            # Adapt based on actual response structure if different\n",
    "            elif hasattr(response, 'embedding') and isinstance(response.embedding, list):\n",
    "                 logger.info(f\"Successfully embedded {len(response.embedding)} documents (object access).\")\n",
    "                 # Assuming response.embedding contains Embedding objects with a 'values' attribute\n",
    "                 return [list(e.values) for e in response.embedding if hasattr(e, 'values')]\n",
    "\n",
    "            else:\n",
    "                 logger.error(f\"Unexpected embedding response format: {response}\")\n",
    "                 raise ValueError(\"Failed to extract embeddings from response.\")\n",
    "\n",
    "        except TypeError as te: # Catch specific TypeError from input validation\n",
    "             logger.error(f\"Input type error during embedding: {te}\")\n",
    "             raise # Re-raise the type error\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error during embedding call: {e}\")\n",
    "            # Propagate the error or return empty list based on desired robustness\n",
    "            raise # Re-raise the exception after logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 6. Menu Data Definition - CafeGenius Full Menu\n",
    "# ==============================================================================\n",
    "\n",
    "menu_data = [\n",
    "    # Coffee\n",
    "    {\"name\": \"Espresso\", \"category\": \"Coffee\", \"description\": \"A concentrated form of coffee served in small, strong shots.\", \"price\": 3.50, \"available\": True, \"modifiers\": [\"Single\", \"Double\", \"Triple\", \"Decaf\", \"Regular\"]},\n",
    "    {\"name\": \"Americano\", \"category\": \"Coffee\", \"description\": \"Espresso diluted with hot water for a smoother taste.\", \"price\": 3.75, \"available\": True, \"modifiers\": [\"Hot\", \"Iced\", \"Decaf\"]},\n",
    "    {\"name\": \"Latte\", \"category\": \"Coffee\", \"description\": \"Espresso with steamed milk and a light layer of foam.\", \"price\": 4.50, \"available\": True, \"modifiers\": [\"Whole Milk\", \"2%\", \"Skim\", \"Oat Milk\", \"Almond\", \"Vanilla\", \"Caramel\", \"Hazelnut\"]},\n",
    "    {\"name\": \"Cappuccino\", \"category\": \"Coffee\", \"description\": \"Equal parts espresso, steamed milk, and foam.\", \"price\": 4.25, \"available\": True, \"modifiers\": [\"Whole Milk\", \"2%\", \"Oat Milk\", \"Almond\", \"Cinnamon\", \"Chocolate\"]},\n",
    "    {\"name\": \"Flat White\", \"category\": \"Coffee\", \"description\": \"Ristretto shots topped with steamed milk and a velvety microfoam.\", \"price\": 4.25, \"available\": True, \"modifiers\": [\"Whole Milk\", \"Oat Milk\", \"Almond\"]},\n",
    "    {\"name\": \"Cold Brew\", \"category\": \"Coffee\", \"description\": \"Coffee brewed with cold water over an extended period.\", \"price\": 4.75, \"available\": True, \"modifiers\": [\"Sweet Cream\", \"Vanilla\", \"Caramel\", \"Oat Milk\"]},\n",
    "    {\"name\": \"Mocha\", \"category\": \"Coffee\", \"description\": \"Espresso with chocolate syrup and steamed milk, topped with whipped cream.\", \"price\": 4.95, \"available\": True, \"modifiers\": [\"Dark Chocolate\", \"White Chocolate\", \"Oat Milk\", \"Almond Milk\", \"No Whip\"]},\n",
    "\n",
    "    # Tea\n",
    "    {\"name\": \"Chai Latte\", \"category\": \"Tea\", \"description\": \"Spiced tea concentrate with steamed milk.\", \"price\": 4.50, \"available\": True, \"modifiers\": [\"Whole Milk\", \"2%\", \"Oat Milk\", \"Almond\", \"Extra Spicy\"]},\n",
    "    {\"name\": \"Matcha Latte\", \"category\": \"Tea\", \"description\": \"Japanese green tea powder with steamed milk.\", \"price\": 5.00, \"available\": True, \"modifiers\": [\"Whole Milk\", \"2%\", \"Oat Milk\", \"Almond\", \"Vanilla\"]},\n",
    "    {\"name\": \"Earl Grey\", \"category\": \"Tea\", \"description\": \"Classic black tea infused with bergamot citrus.\", \"price\": 3.25, \"available\": True, \"modifiers\": [\"Honey\", \"Lemon\", \"Milk\"]},\n",
    "    {\"name\": \"Herbal Tea\", \"category\": \"Tea\", \"description\": \"Caffeine-free blend of herbs and botanicals.\", \"price\": 3.00, \"available\": True, \"modifiers\": [\"Peppermint\", \"Chamomile\", \"Lemon Ginger\"]},\n",
    "    {\"name\": \"Iced Tea\", \"category\": \"Tea\", \"description\": \"Refreshing black tea served over ice.\", \"price\": 3.50, \"available\": True, \"modifiers\": [\"Sweetened\", \"Unsweetened\", \"Lemon\", \"Peach\", \"Raspberry\"]},\n",
    "\n",
    "    # Pastries\n",
    "    {\"name\": \"Croissant\", \"category\": \"Pastry\", \"description\": \"Buttery, flaky pastry of French origin.\", \"price\": 3.25, \"available\": True, \"modifiers\": [\"Butter\", \"Almond\", \"Chocolate\"]},\n",
    "    {\"name\": \"Blueberry Muffin\", \"category\": \"Pastry\", \"description\": \"Sweet breakfast bread with blueberries.\", \"price\": 3.50, \"available\": True, \"modifiers\": [\"Warmed\"]},\n",
    "    {\"name\": \"Banana Bread\", \"category\": \"Pastry\", \"description\": \"Moist banana bread with a hint of cinnamon.\", \"price\": 3.75, \"available\": True, \"modifiers\": [\"Warmed\", \"Add Butter\"]},\n",
    "    {\"name\": \"Cinnamon Roll\", \"category\": \"Pastry\", \"description\": \"Swirled pastry with cinnamon and icing.\", \"price\": 4.00, \"available\": True, \"modifiers\": [\"Extra Icing\", \"Warmed\"]},\n",
    "\n",
    "    # Food\n",
    "    {\"name\": \"Avocado Toast\", \"category\": \"Food\", \"description\": \"Toasted bread topped with mashed avocado.\", \"price\": 7.50, \"available\": True, \"modifiers\": [\"Add Egg\", \"Add Tomato\", \"Add Feta\"]},\n",
    "    {\"name\": \"Breakfast Sandwich\", \"category\": \"Food\", \"description\": \"Egg and cheese on a croissant or English muffin.\", \"price\": 6.50, \"available\": True, \"modifiers\": [\"Bacon\", \"Sausage\", \"Avocado\"]},\n",
    "    {\"name\": \"Quiche\", \"category\": \"Food\", \"description\": \"Savory egg tart with cheese and seasonal vegetables.\", \"price\": 6.75, \"available\": True, \"modifiers\": [\"Vegetarian\", \"Add Ham\", \"Gluten-Free\"]},\n",
    "    {\"name\": \"Yogurt Parfait\", \"category\": \"Food\", \"description\": \"Layers of Greek yogurt, granola, and seasonal fruit.\", \"price\": 5.50, \"available\": True, \"modifiers\": [\"Honey\", \"No Granola\", \"Add Chia Seeds\"]},\n",
    "    # Add more items as needed \n",
    "]\n",
    "\n",
    "\n",
    "logger.info(f\"Loaded {len(menu_data)} menu items.\")\n",
    "\n",
    "# Create detailed descriptions for RAG\n",
    "menu_descriptions = []\n",
    "for item in menu_data:\n",
    "    description = f\"{item['name']}: {item['description']} Priced at ${item['price']:.2f}.\"\n",
    "    if item.get('modifiers'): # Use .get for safety\n",
    "        description += f\" Available modifiers: {', '.join(item['modifiers'])}.\"\n",
    "    menu_descriptions.append(description)\n",
    "\n",
    "\n",
    "logger.info(f\"Generated {len(menu_descriptions)} descriptions for RAG.\")\n",
    "### LOGGING - Enable/ Disable\n",
    "print(\"Sample menu descriptions for RAG:\")\n",
    "for i in range(min(3, len(menu_descriptions))):\n",
    "    print(f\"- {menu_descriptions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 7. ChromaDB Setup for RAG\n",
    "# ==============================================================================\n",
    "DB_NAME = \"cafegenius_menu_db\"\n",
    "# Use ephemeral client for simplicity in notebooks, or PersistentClient for saving DB\n",
    "# chroma_client = chromadb.Client() # In-memory\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db_cafe\") # Saves to disk\n",
    "\n",
    "# Instantiate the embedding function\n",
    "# Pass the API key if not configured globally, otherwise it uses the global config\n",
    "embed_fn = GeminiEmbeddingFunction(api_key=GOOGLE_API_KEY if 'GOOGLE_API_KEY' in locals() else None)\n",
    "\n",
    "# Create or get the collection\n",
    "try:\n",
    "    # Set the embedding function task type appropriately for adding documents\n",
    "    embed_fn.task_type = \"retrieval_document\"\n",
    "    db = chroma_client.get_or_create_collection(\n",
    "        name=DB_NAME,\n",
    "        embedding_function=embed_fn,\n",
    "        metadata={\"hnsw:space\": \"cosine\"} # Specify distance metric if needed\n",
    "    )\n",
    "    logger.info(f\"ChromaDB collection '{DB_NAME}' created or retrieved.\")\n",
    "\n",
    "    # Add menu descriptions to the vector database (only if collection is new or empty)\n",
    "    if db.count() == 0:\n",
    "         logger.info(f\"Adding {len(menu_descriptions)} documents to ChromaDB...\")\n",
    "         db.add(\n",
    "             documents=menu_descriptions,\n",
    "             ids=[item['name'] for item in menu_data] # Use item names as IDs\n",
    "             # Optionally add metadata: metadatas=[{\"category\": item[\"category\"], \"price\": item[\"price\"]} for item in menu_data]\n",
    "         )\n",
    "         logger.info(\"Documents added successfully.\")\n",
    "    else:\n",
    "         logger.info(f\"Collection '{DB_NAME}' already contains {db.count()} documents. Skipping add.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Failed to setup ChromaDB or add documents: {e}\")\n",
    "    # Handle error appropriately - maybe exit or proceed without RAG\n",
    "\n",
    "# Verification Step\n",
    "try:\n",
    "    menu_documents_check = db.get(ids=[item['name'] for item in menu_data[:3]]) # Get first 3 by ID\n",
    "    logger.info(f\"ChromaDB Verification: Retrieved {len(menu_documents_check.get('documents', []))} docs.\")\n",
    "    print(\"Sample documents from ChromaDB:\")\n",
    "    print(menu_documents_check.get('documents'))\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error verifying ChromaDB content: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 8. RAG Search Function\n",
    "# ==============================================================================\n",
    "# Improvement 2: Enhanced error handling and return type\n",
    "def search_menu(query: str, n_results: int = 3) -> Optional[List[str]]:\n",
    "    \"\"\"Search the menu database for relevant items using vector similarity.\"\"\"\n",
    "    if 'db' not in locals() or db is None:\n",
    "         logger.error(\"ChromaDB collection 'db' is not available for searching.\")\n",
    "         return None # Cannot search\n",
    "\n",
    "    # Set the embedding function task type for querying\n",
    "    embed_fn.task_type = \"retrieval_query\"\n",
    "    logger.info(f\"Performing RAG search for query: '{query}' with n_results={n_results}\")\n",
    "\n",
    "    try:\n",
    "        results = db.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results,\n",
    "            include=['documents'] # Only fetch documents\n",
    "        )\n",
    "        # Check results structure carefully\n",
    "        if results and isinstance(results.get('documents'), list) and results['documents']:\n",
    "            # results['documents'] is a list containing one list of results (for the one query)\n",
    "            retrieved_docs = results['documents'][0]\n",
    "            logger.info(f\"RAG Search found {len(retrieved_docs)} documents.\")\n",
    "            return retrieved_docs\n",
    "        else:\n",
    "            logger.info(f\"No relevant documents found via RAG for query: '{query}'\")\n",
    "            return [] # Return empty list if no documents found\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the full exception traceback for debugging\n",
    "        logger.exception(f\"ChromaDB RAG search error for query '{query}': {e}\")\n",
    "        return None # Indicate failure occurred\n",
    "\n",
    "### LOGGING - Enable/ Disable        \n",
    "### Test the search function\n",
    "print(\"\\nTesting RAG Search:\")\n",
    "test_query = \"Something with espresso and milk\"\n",
    "search_results = search_menu(test_query)\n",
    "if search_results is not None:\n",
    "     print(f\"Search results for '{test_query}':\")\n",
    "     for doc in search_results:\n",
    "         print(f\"- {doc}\")\n",
    "else:\n",
    "     print(\"Search failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 9. Order Management Class\n",
    "# ==============================================================================\n",
    "# Improvement 1: Using the dedicated Order class\n",
    "class Order:\n",
    "    \"\"\"Manages the items in a customer's order.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.items: List[Dict[str, Any]] = []\n",
    "        logger.info(\"Order initialized.\")\n",
    "\n",
    "    def add_items(self, new_items: List[Dict[str, Any]]):\n",
    "        \"\"\"Adds validated items to the order.\"\"\"\n",
    "        if new_items:\n",
    "             self.items.extend(new_items)\n",
    "             logger.info(f\"Added {len(new_items)} items to order. Current count: {len(self.items)}\")\n",
    "        else:\n",
    "             logger.warning(\"Attempted to add an empty list of items to the order.\")\n",
    "\n",
    "\n",
    "    def get_total(self) -> float:\n",
    "        \"\"\"Calculates the total price of the order.\"\"\"\n",
    "        if not self.items:\n",
    "            return 0.0\n",
    "        return sum(item.get(\"price\", 0.0) * item.get(\"quantity\", 1) for item in self.items)\n",
    "\n",
    "    def display(self) -> str:\n",
    "        \"\"\"Formats the current order for display.\"\"\"\n",
    "        if not self.items:\n",
    "            return \"Your order is currently empty.\"\n",
    "\n",
    "        order_text = \"**Your Current Order:**\\n\\n\" # Use Markdown\n",
    "        for item in self.items:\n",
    "            item_name = item.get(\"name\", \"Unknown Item\")\n",
    "            quantity = item.get(\"quantity\", 1)\n",
    "            price = item.get(\"price\", 0.0)\n",
    "            modifiers = item.get(\"modifiers\", [])\n",
    "\n",
    "            modifiers_text = \"\"\n",
    "            if modifiers:\n",
    "                modifiers_text = f\" (Modifiers: {', '.join(modifiers)})\"\n",
    "\n",
    "            item_total = price * quantity\n",
    "            order_text += f\"- {quantity}x {item_name}{modifiers_text}: ${item_total:.2f}\\n\"\n",
    "\n",
    "        total = self.get_total()\n",
    "        order_text += f\"\\n**Total: ${total:.2f}**\"\n",
    "        logger.info(f\"Displaying order with {len(self.items)} items, total: ${total:.2f}\")\n",
    "        return order_text\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"Checks if the order is empty.\"\"\"\n",
    "        return not self.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 10. Tool Function Definitions (for Gemini Function Calling)\n",
    "# ==============================================================================\n",
    "\n",
    "def get_menu() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Retrieves the full cafe menu, organized by category,\n",
    "    including names, prices, and modifiers for available items.\n",
    "    \"\"\"\n",
    "    logger.info(\"Executing 'get_menu' function.\")\n",
    "    categories: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for item in menu_data:\n",
    "        if item.get(\"available\", False):\n",
    "            category = item.get(\"category\", \"Uncategorized\")\n",
    "            if category not in categories:\n",
    "                categories[category] = []\n",
    "            categories[category].append({\n",
    "                \"name\": item.get(\"name\", \"N/A\"),\n",
    "                \"price\": item.get(\"price\", 0.0),\n",
    "                \"modifiers\": item.get(\"modifiers\", [])\n",
    "            })\n",
    "    if not categories:\n",
    "        logger.warning(\"'get_menu' found no available items.\")\n",
    "        return {\"message\": \"Sorry, it seems nothing is available on the menu right now.\"}\n",
    "    return categories\n",
    "\n",
    "\n",
    "def get_item_details(item_name: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Gets detailed information about a specific menu item by its name.\n",
    "    Returns the item's details if found, otherwise None.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Executing 'get_item_details' for: {item_name}\")\n",
    "    item_name_lower = item_name.lower()\n",
    "    # Exact match first\n",
    "    for item in menu_data:\n",
    "        if item.get(\"name\", \"\").lower() == item_name_lower:\n",
    "            if item.get(\"available\", False):\n",
    "                logger.info(f\"Found exact match for available item: {item_name}\")\n",
    "                return item # Return full item details\n",
    "            else:\n",
    "                logger.warning(f\"Found exact match for '{item_name}', but it's unavailable.\")\n",
    "                return {\"name\": item_name, \"available\": False, \"message\": f\"Sorry, {item_name} is currently unavailable.\"}\n",
    "\n",
    "    # If no exact match, try RAG search as a fallback (optional, can be demanding)\n",
    "    logger.warning(f\"Exact match not found for '{item_name}'. Trying RAG search...\")\n",
    "    query = f\"Detailed information about the menu item: {item_name}\"\n",
    "    similar_item_docs = search_menu(query, n_results=1) # Get the most similar description\n",
    "\n",
    "    if similar_item_docs:\n",
    "        try:\n",
    "            # Attempt to parse the item name from the RAG result\n",
    "            # This assumes format \"Item Name: Description...\"\n",
    "            retrieved_name = similar_item_docs[0].split(\":\")[0].strip()\n",
    "            logger.info(f\"RAG suggested similar item: {retrieved_name}\")\n",
    "            # Find this suggested item in the actual menu data\n",
    "            for item in menu_data:\n",
    "                if item.get(\"name\", \"\").lower() == retrieved_name.lower() and item.get(\"available\", True):\n",
    "                     logger.info(f\"Returning details for RAG-suggested item: {retrieved_name}\")\n",
    "                     # Inform the user it's a suggestion\n",
    "                     item_with_note = item.copy()\n",
    "                     item_with_note[\"note\"] = f\"Showing details for '{retrieved_name}', which seemed similar to your request for '{item_name}'.\"\n",
    "                     return item_with_note\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing RAG result for similar item details: {e}\")\n",
    "\n",
    "    # If still not found\n",
    "    logger.error(f\"Item '{item_name}' could not be found on the menu.\")\n",
    "    return {\"found\": False, \"message\": f\"Sorry, I couldn't find '{item_name}' on our menu. Please check the spelling or ask for the main menu.\"}\n",
    "    # Returning a dictionary helps structure the \"not found\" response for the LLM\n",
    "\n",
    "\n",
    "def add_to_order(items: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Adds items to the customer's order after validating item names and modifiers.\n",
    "    Returns a dictionary containing lists of successfully added items ('valid_items')\n",
    "    and items that could not be added ('invalid_items_details').\n",
    "    \"\"\"\n",
    "    logger.info(f\"Executing 'add_to_order' for {len(items)} requested item(s).\")\n",
    "    valid_items_added: List[Dict[str, Any]] = []\n",
    "    invalid_items_details: List[Dict[str, Any]] = []\n",
    "\n",
    "    for requested_item in items:\n",
    "        item_name = requested_item.get(\"name\", \"\")\n",
    "        requested_modifiers = requested_item.get(\"modifiers\", [])\n",
    "        quantity = requested_item.get(\"quantity\", 1)\n",
    "\n",
    "        if not item_name or quantity < 1:\n",
    "            logger.warning(f\"Invalid request format in 'add_to_order': {requested_item}\")\n",
    "            invalid_items_details.append({\"requested\": requested_item, \"reason\": \"Missing name or invalid quantity.\"})\n",
    "            continue\n",
    "\n",
    "        # Find the item in menu_data (case-insensitive)\n",
    "        menu_item_found = None\n",
    "        item_name_lower = item_name.lower()\n",
    "        for m_item in menu_data:\n",
    "            if m_item.get(\"name\", \"\").lower() == item_name_lower:\n",
    "                menu_item_found = m_item\n",
    "                break\n",
    "\n",
    "        if menu_item_found and menu_item_found.get(\"available\", False):\n",
    "            # Item exists and is available, validate modifiers\n",
    "            valid_modifiers_for_item = []\n",
    "            invalid_modifiers_for_item = []\n",
    "            available_modifiers = menu_item_found.get(\"modifiers\", [])\n",
    "\n",
    "            for mod in requested_modifiers:\n",
    "                # Case-insensitive modifier check\n",
    "                mod_found = False\n",
    "                for avail_mod in available_modifiers:\n",
    "                    if mod.lower() == avail_mod.lower():\n",
    "                        valid_modifiers_for_item.append(avail_mod) # Use the canonical name\n",
    "                        mod_found = True\n",
    "                        break\n",
    "                if not mod_found:\n",
    "                    invalid_modifiers_for_item.append(mod)\n",
    "\n",
    "            # Prepare the item to be potentially added\n",
    "            item_to_add = {\n",
    "                \"name\": menu_item_found[\"name\"], # Use canonical name\n",
    "                \"price\": menu_item_found.get(\"price\", 0.0),\n",
    "                \"quantity\": quantity,\n",
    "                \"modifiers\": valid_modifiers_for_item\n",
    "            }\n",
    "            valid_items_added.append(item_to_add)\n",
    "\n",
    "            # Log if any requested modifiers were invalid for this valid item\n",
    "            if invalid_modifiers_for_item:\n",
    "                 logger.warning(f\"Invalid modifiers requested for '{item_name}': {invalid_modifiers_for_item}\")\n",
    "                 # Optionally add details about invalid modifiers to the response structure\n",
    "                 invalid_items_details.append({\n",
    "                     \"requested_item_name\": item_name,\n",
    "                     \"reason\": \"Some modifiers were invalid.\",\n",
    "                     \"invalid_modifiers\": invalid_modifiers_for_item,\n",
    "                     \"added_item\": item_to_add # Show what was added despite invalid mods\n",
    "                 })\n",
    "\n",
    "        else:\n",
    "            # Item not found or not available\n",
    "            reason = \"Item not found on menu.\" if not menu_item_found else f\"Item '{item_name}' is currently unavailable.\"\n",
    "            logger.warning(f\"Could not add item '{item_name}'. Reason: {reason}\")\n",
    "            invalid_items_details.append({\"requested_item_name\": item_name, \"reason\": reason})\n",
    "\n",
    "    # Construct the result dictionary\n",
    "    result = {\n",
    "        \"status\": f\"Processed {len(items)} requests. Added {len(valid_items_added)} items.\",\n",
    "        \"valid_items\": valid_items_added, # These should be added to the Order object by the calling code\n",
    "        \"invalid_items_details\": invalid_items_details\n",
    "    }\n",
    "    logger.info(f\"Finished 'add_to_order'. Result: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_recommendations(preferences: List[str], dietary_restrictions: List[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Gets personalized recommendations based on customer preferences and optional dietary restrictions,\n",
    "    using RAG search on menu descriptions.\n",
    "    \"\"\"\n",
    "    if dietary_restrictions is None:\n",
    "        dietary_restrictions = []\n",
    "\n",
    "    logger.info(f\"Executing 'get_recommendations'. Preferences: {preferences}, Restrictions: {dietary_restrictions}\")\n",
    "\n",
    "    # Construct a query for RAG\n",
    "    query = f\"Recommend cafe items for someone who likes {', '.join(preferences)}\"\n",
    "    if dietary_restrictions:\n",
    "        query += f\" and needs options suitable for {', '.join(dietary_restrictions)} dietary restrictions (e.g., gluten-free, vegan, dairy-free).\"\n",
    "    query += \". Consider item descriptions, ingredients, and common associations.\" # Add more context\n",
    "\n",
    "    # Get relevant item descriptions from the vector database\n",
    "    relevant_descriptions = search_menu(query, n_results=5) # Increase results for better filtering\n",
    "\n",
    "    if relevant_descriptions is None:\n",
    "         return {\"error\": \"Recommendation search failed. Please try again later.\"}\n",
    "    if not relevant_descriptions:\n",
    "         return {\"message\": \"I couldn't find specific recommendations based on that. Maybe try broadening your preferences?\"}\n",
    "\n",
    "\n",
    "    # Extract item names and retrieve full details from menu_data\n",
    "    recommended_items_details: List[Dict[str, Any]] = []\n",
    "    seen_names = set()\n",
    "\n",
    "    for desc in relevant_descriptions:\n",
    "        try:\n",
    "            # Attempt to robustly extract item name (assuming \"Name: Description...\" format)\n",
    "            item_name = desc.split(\":\")[0].strip()\n",
    "            if item_name and item_name not in seen_names:\n",
    "                 # Find the full item details in menu_data\n",
    "                 item_found = None\n",
    "                 item_name_lower = item_name.lower()\n",
    "                 for item in menu_data:\n",
    "                     if item.get(\"name\",\"\").lower() == item_name_lower and item.get(\"available\", True):\n",
    "                         item_found = item\n",
    "                         break\n",
    "\n",
    "                 if item_found:\n",
    "                     # Basic filtering (can be improved with more metadata/logic)\n",
    "                     # e.g., check if description mentions dietary needs if provided\n",
    "                     passes_filter = True # Add filtering logic here if needed\n",
    "                     if passes_filter:\n",
    "                          recommended_items_details.append(item_found)\n",
    "                          seen_names.add(item_name)\n",
    "\n",
    "                 # Limit the number of recommendations returned\n",
    "                 if len(recommended_items_details) >= 3: # Limit to top 3 relevant items\n",
    "                     break\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not parse item name from description '{desc[:50]}...': {e}\")\n",
    "            continue # Skip this description\n",
    "\n",
    "    if not recommended_items_details:\n",
    "         return {\"message\": \"Based on the search, I don't have specific recommendations matching everything. You could check the full menu!\"}\n",
    "    else:\n",
    "         logger.info(f\"Returning {len(recommended_items_details)} recommendations.\")\n",
    "         return {\"recommendations\": recommended_items_details}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 11. Define Tools for Gemini Model (Corrected Schema)\n",
    "# ==============================================================================\n",
    "# Ensure glm (google.ai.generativelanguage) is imported\n",
    "\n",
    "tools_list = [\n",
    "    glm.Tool(\n",
    "        function_declarations=[\n",
    "            glm.FunctionDeclaration(\n",
    "                name=\"get_menu\",\n",
    "                description=\"Retrieves the full cafe menu, organized by category, including names, prices, and modifiers for available items.\",\n",
    "                parameters=glm.Schema(type=glm.Type.OBJECT, properties={}) # No parameters needed\n",
    "            ),\n",
    "            glm.FunctionDeclaration(\n",
    "                name=\"get_item_details\",\n",
    "                description=\"Gets detailed information (description, price, modifiers, availability) about a specific menu item by its name.\",\n",
    "                parameters=glm.Schema(\n",
    "                    type=glm.Type.OBJECT,\n",
    "                    properties={\n",
    "                        \"item_name\": glm.Schema(type=glm.Type.STRING, description=\"The exact name of the menu item to look up.\")\n",
    "                    },\n",
    "                    required=[\"item_name\"]\n",
    "                )\n",
    "            ),\n",
    "            glm.FunctionDeclaration(\n",
    "                name=\"add_to_order\",\n",
    "                description=\"Adds one or more items to the customer's current order. Specify item name, quantity, and any desired modifiers.\",\n",
    "                parameters=glm.Schema(\n",
    "                    type=glm.Type.OBJECT,\n",
    "                    properties={\n",
    "                        \"items\": glm.Schema(\n",
    "                            type=glm.Type.ARRAY,\n",
    "                            description=\"A list of items to add to the order.\",\n",
    "                            items=glm.Schema(\n",
    "                                type=glm.Type.OBJECT,\n",
    "                                properties={\n",
    "                                    \"name\": glm.Schema(type=glm.Type.STRING, description=\"The name of the menu item.\"),\n",
    "                                \n",
    "                                    \"quantity\": glm.Schema(type=glm.Type.INTEGER, description=\"How many of this item to order (default will be handled by the function if not provided).\"),\n",
    "                                    \"modifiers\": glm.Schema(\n",
    "                                        type=glm.Type.ARRAY,\n",
    "                                        description=\"List of optional modifiers (e.g., 'Oat Milk', 'Extra Shot', 'Warmed').\",\n",
    "                                        items=glm.Schema(type=glm.Type.STRING)\n",
    "                                    )\n",
    "                                },\n",
    "                                required=[\"name\"] # Quantity is not strictly required here; handled in function\n",
    "                            )\n",
    "                        )\n",
    "                    },\n",
    "                    required=[\"items\"]\n",
    "                )\n",
    "            ),\n",
    "            glm.FunctionDeclaration(\n",
    "                name=\"get_recommendations\",\n",
    "                description=\"Suggests menu items based on customer preferences (e.g., 'sweet', 'strong coffee', 'breakfast') and optional dietary restrictions (e.g., 'vegan', 'gluten-free').\",\n",
    "                parameters=glm.Schema(\n",
    "                    type=glm.Type.OBJECT,\n",
    "                    properties={\n",
    "                        \"preferences\": glm.Schema(\n",
    "                            type=glm.Type.ARRAY,\n",
    "                            description=\"List of customer preferences (flavors, meal types, etc.).\",\n",
    "                            items=glm.Schema(type=glm.Type.STRING)\n",
    "                        ),\n",
    "                        \"dietary_restrictions\": glm.Schema(\n",
    "                            type=glm.Type.ARRAY,\n",
    "                            description=\"List of dietary needs or restrictions (optional).\",\n",
    "                            items=glm.Schema(type=glm.Type.STRING)\n",
    "                        )\n",
    "                    },\n",
    "                    required=[\"preferences\"]\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "logger.info(f\"Defined {len(tools_list[0].function_declarations)} tools for the Gemini model (schema corrected).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 12. System Prompt and Model Configuration\n",
    "# ==============================================================================\n",
    "system_prompt = \"\"\"You are CafeGenius, a cheerful, knowledgeable, and efficient AI assistant for our cafe. Your goal is to help customers explore the menu, make selections, get recommendations, and place orders smoothly.\n",
    "\n",
    "**Key Instructions:**\n",
    "* **Use Tools:** Rely on your available tools (`get_menu`, `get_item_details`, `add_to_order`, `get_recommendations`) to answer questions accurately about the menu, item details, ordering, and recommendations. Don't guess menu details or availability.\n",
    "* **Clarity:** When providing menu information or order summaries, format it clearly using Markdown (like bullet points or categories).\n",
    "* **Order Confirmation:** When adding items via `add_to_order`, clearly state what was successfully added and mention any issues (like invalid items or modifiers) reported by the tool.\n",
    "* **Recommendations:** Base recommendations on the results from the `get_recommendations` tool. Explain *why* you're recommending something based on the customer's request.\n",
    "* **Tone:** Be friendly, polite, and helpful, like a great barista. Keep responses concise but informative.\n",
    "* **Limitations:** If you cannot fulfill a request (e.g., item not found, RAG search fails), politely explain the issue and suggest alternatives (like viewing the full menu or rephrasing). Do not make up information.\n",
    "\"\"\"\n",
    "\n",
    "# Configure Generation Settings (example, adjust as needed)\n",
    "generation_config = genai.GenerationConfig(\n",
    "    temperature=0.7, # Balance creativity and coherence\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    # max_output_tokens=1024, # Optional: Limit response length\n",
    "    # stop_sequences=[\"User:\", \"\\n\\n\"], # Optional: Define stop sequences\n",
    ")\n",
    "\n",
    "safety_settings = [ # Adjust safety settings based on requirements\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "]\n",
    "\n",
    "\n",
    "logger.info(\"System prompt and generation configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 13. Main Chat Function\n",
    "# ==============================================================================\n",
    "\n",
    "# Mapping function names to actual Python functions\n",
    "available_functions = {\n",
    "    \"get_menu\": get_menu,\n",
    "    \"get_item_details\": get_item_details,\n",
    "    \"add_to_order\": add_to_order,\n",
    "    \"get_recommendations\": get_recommendations,\n",
    "}\n",
    "\n",
    "def handle_function_call(function_call: glm.FunctionCall, current_order: Order) -> glm.Part:\n",
    "    \"\"\"Handles executing a function call from the Gemini model.\"\"\"\n",
    "    function_name = function_call.name\n",
    "    args_dict = {k: v for k, v in function_call.args.items()}\n",
    "    logger.info(f\"Received function call: {function_name} with args: {args_dict}\")\n",
    "\n",
    "    func = available_functions.get(function_name)\n",
    "    if not func:\n",
    "        logger.error(f\"Unknown function called: {function_name}\")\n",
    "        result = {\"error\": f\"Unknown function name: {function_name}\"}\n",
    "    else:\n",
    "        try:\n",
    "            # Call the appropriate Python function with its arguments\n",
    "            result = func(**args_dict)\n",
    "            logger.info(f\"Function '{function_name}' executed successfully.\")\n",
    "\n",
    "            # --- Improvement 1: Integrate Order Class ---\n",
    "            # If add_to_order was called, update the actual order object\n",
    "            if function_name == \"add_to_order\" and isinstance(result, dict) and \"valid_items\" in result:\n",
    "                items_to_officially_add = result.get(\"valid_items\", [])\n",
    "                if items_to_officially_add:\n",
    "                     current_order.add_items(items_to_officially_add)\n",
    "                     logger.info(f\"Updated Order object with {len(items_to_officially_add)} items.\")\n",
    "                # The 'result' dict already contains info about valid/invalid items,\n",
    "                # which will be sent back to the LLM below.\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error executing function '{function_name}': {e}\")\n",
    "            result = {\"error\": f\"Error during execution of {function_name}: {str(e)}\"}\n",
    "\n",
    "      # Ensure the result is serializable (convert to dict if needed)\n",
    "    if not isinstance(result, dict):\n",
    "        # Handle cases where functions might return lists, strings, None, etc.\n",
    "        # Wrap them in a dictionary for consistent processing by the LLM.\n",
    "        if result is None:\n",
    "            result = {\"status\": \"Operation completed, no specific data returned.\"}\n",
    "        elif isinstance(result, list):\n",
    "             result = {\"items\": result} # Example wrapping for a list result\n",
    "        else:\n",
    "             result = {\"result\": str(result)} # Default wrapping\n",
    "\n",
    "    # Convert the result dictionary to a Protobuf Struct\n",
    "    try:\n",
    "        response_struct = struct_pb2.Struct()\n",
    "        response_struct.update(result)\n",
    "        function_response = glm.FunctionResponse(name=function_name, response=response_struct)\n",
    "        return glm.Part(function_response=function_response)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error converting result for {function_name} to Struct: {e}\")\n",
    "        # Fallback: return an error message within the FunctionResponse structure\n",
    "        error_struct = struct_pb2.Struct()\n",
    "        error_struct.update({\"error\": f\"Failed to serialize result: {str(e)}\"})\n",
    "        function_response = glm.FunctionResponse(name=function_name, response=error_struct)\n",
    "        return glm.Part(function_response=function_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# 14. Initiates and manages the chat session with the CafeGenius assistant.\n",
    "#############################################################################\n",
    "def chat_with_cafe_genius():\n",
    "   \n",
    "\n",
    "    if not GOOGLE_API_KEY:\n",
    "         print(\"Cannot start chat: GOOGLE_API_KEY is not configured.\")\n",
    "         return\n",
    "\n",
    "    # Select the model - Check availability and choose appropriately\n",
    "    # List models - requires API call, handle potential errors\n",
    "    available_models = []\n",
    "    try:\n",
    "        # Note: genai.list_models() might return an iterator or list depending on version\n",
    "        for m in genai.list_models():\n",
    "             # Check if the model supports 'generateContent' (required for chat)\n",
    "             if 'generateContent' in m.supported_generation_methods:\n",
    "                  available_models.append(m.name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to list available models: {e}\")\n",
    "        print(\"Error: Could not retrieve list of available models. Cannot proceed.\")\n",
    "        return\n",
    "\n",
    "    # Choose a preferred model, falling back if necessary\n",
    "    preferred_model = \"models/gemini-2.0-flash\" # Or \"models/gemini-1.5-pro-latest\"\n",
    "    fallback_model = \"models/gemini-1.5-flash-latest\" # A generally available fallback\n",
    "\n",
    "    if preferred_model in available_models:\n",
    "         model_to_use = preferred_model\n",
    "    elif fallback_model in available_models:\n",
    "         model_to_use = fallback_model\n",
    "    else:\n",
    "         # Try finding any 'pro' model as a last resort\n",
    "         pro_models = [m for m in available_models if 'pro' in m and 'embedding' not in m]\n",
    "         if pro_models:\n",
    "             model_to_use = pro_models[0]\n",
    "         else:\n",
    "             logger.error(f\"Could not find a suitable Gemini model. Available: {available_models}\")\n",
    "             print(\"Error: No suitable Gemini model found (tried 2.0-flash , 1.5-flash). Cannot start chat.\")\n",
    "             return\n",
    "\n",
    "    print(f\"--> CafeGenius Assistant is using: {model_to_use} , Gemini Model.\")\n",
    "    # Keep the existing logger line as well:\n",
    "    logger.info(f\"Using Gemini model: {model_to_use}\")\n",
    "\n",
    "    # Initialize the chat model\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=model_to_use,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        tools=tools_list,\n",
    "        system_instruction=system_prompt # Pass system prompt here\n",
    "    )\n",
    "\n",
    "    # Start a chat session (maintains history)\n",
    "    chat = model.start_chat(enable_automatic_function_calling=False) # Manual control over function calls\n",
    "    logger.info(\"Chat session started.\")\n",
    "\n",
    "    # Improvement 1: Instantiate the Order class here\n",
    "    current_order = Order()\n",
    "\n",
    "    def print_boxed_message():\n",
    "        lines = [\n",
    "            \"☕️ Welcome to CafeGenius Assistant V1.0!\",\n",
    "            \"(Developed by: Erwin R. Pasia | erwinpasia@gmail.com)\",\n",
    "            \"\",\n",
    "            \"Hi there! I’m your virtual barista.\",\n",
    "            \"Curious about what’s brewing? Check the menu, get a personalized pick, or place your order anytime.\",\n",
    "            \"\",\n",
    "            \"Just type:\",\n",
    "            \"  'menu'        – View our offerings\",\n",
    "            \"  'recommend'   – Get a drink suggestion\",\n",
    "            \"  'order'       – Start your order\",\n",
    "            \"  'show order'  – Review your current order\",\n",
    "            \"  'exit or bye' – Leave the assistant\",\n",
    "            \"\",\n",
    "            \"For example:\",\n",
    "            \"Step 1: What are on the menu today?\",\n",
    "            \"Step 2: I would like to order Flat White, Mocha, and Latte. No modifiers on them. Add 3 banana bread.\"\n",
    "        ]\n",
    "    \n",
    "        # Find the length of the longest line\n",
    "        max_length = max(len(line) for line in lines)\n",
    "        border = \"─\" * (max_length + 4)\n",
    "\n",
    "        print(\"┌\" + border + \"┐\")\n",
    "        for line in lines:\n",
    "            print(f\"│  {line.ljust(max_length)}  │\")\n",
    "        print(\"└\" + border + \"┘\")\n",
    "\n",
    "        print(\"-\" * (max_length + 10))  # Optional footer line\n",
    "\n",
    "    print_boxed_message()\n",
    "\n",
    "\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"You: \")\n",
    "            print(\"-\" * 28) # Separator\n",
    "\n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"bye\", \"goodbye\"]:\n",
    "                print(\"CafeGenius: Thanks for visiting! Have a great day!\")\n",
    "                if not current_order.is_empty():\n",
    "                     print(\"\\nFinal Order Summary:\")\n",
    "                     display(Markdown(current_order.display())) # Display final order nicely\n",
    "                break\n",
    "\n",
    "            # --- Improvement 1: Use Order class for 'show order' ---\n",
    "            if user_input.lower() in [\"show order\", \"my order\", \"current order\", \"view order\"]:\n",
    "                print(\"CafeGenius:\")\n",
    "                display(Markdown(current_order.display())) # Use the class method\n",
    "                print(\"-\" * 28)\n",
    "                continue\n",
    "\n",
    "            # --- Direct Menu Request ---\n",
    "            if user_input.lower() in [\"menu\", \"show menu\", \"see menu\", \"what's on the menu\", \"what do you have\"]:\n",
    "                 print(\"CafeGenius: Getting the menu for you...\")\n",
    "                 menu_result = get_menu()\n",
    "                 if isinstance(menu_result, dict) and \"message\" in menu_result:\n",
    "                      print(f\"CafeGenius: {menu_result['message']}\")\n",
    "                 elif isinstance(menu_result, dict):\n",
    "                      menu_text = \"**Full Menu:**\\n\\n\"\n",
    "                      for category, items in menu_result.items():\n",
    "                           menu_text += f\"### {category}\\n\" # H3 for categories\n",
    "                           for item in items:\n",
    "                                mods = f\" (Modifiers: {', '.join(item['modifiers'])})\" if item.get('modifiers') else \"\"\n",
    "                                menu_text += f\"- **{item['name']}**: ${item['price']:.2f}{mods}\\n\"\n",
    "                           menu_text += \"\\n\"\n",
    "                      display(Markdown(menu_text))\n",
    "                 else:\n",
    "                      print(\"CafeGenius: Sorry, I couldn't retrieve the menu format correctly.\")\n",
    "                 print(\"-\" * 28)\n",
    "                 continue\n",
    "\n",
    "            # --- Send message to Gemini ---\n",
    "            logger.info(f\"Sending user input to Gemini: '{user_input}'\")\n",
    "            response = chat.send_message(user_input)\n",
    "            logger.info(\"Received response from Gemini.\")\n",
    "\n",
    "            # --- Process Gemini's response (Check for Function Calls) ---\n",
    "            response_part = response.candidates[0].content.parts[0]\n",
    "\n",
    "            if hasattr(response_part, 'function_call') and response_part.function_call:\n",
    "                 function_call = response_part.function_call\n",
    "                 logger.info(\"Gemini requested a function call.\")\n",
    "\n",
    "             \n",
    "                 api_request_part = handle_function_call(function_call, current_order)\n",
    "\n",
    "\n",
    "                 logger.info(f\"Sending function response back to Gemini for function: {function_call.name}\")\n",
    "                 response = chat.send_message(api_request_part)\n",
    "                 logger.info(\"Received final response from Gemini after function call.\")\n",
    "\n",
    "                 # Process the final text response after the function call cycle\n",
    "                 final_text = response.candidates[0].content.parts[0].text\n",
    "                 print(f\"CafeGenius: {final_text}\")\n",
    "                 display(Markdown(final_text)) # Display nicely\n",
    "\n",
    "            elif hasattr(response_part, 'text'):\n",
    "                 # --- Handle regular text response ---\n",
    "                 text_response = response_part.text\n",
    "                 logger.info(\"Received text response from Gemini.\")\n",
    "                 print(\"CafeGenius:\")\n",
    "                 display(Markdown(text_response)) # Display nicely\n",
    "            else:\n",
    "                 # Handle unexpected response content (e.g., blocked content)\n",
    "                 logger.warning(f\"Received unexpected response part: {response_part}\")\n",
    "                 print(\"CafeGenius: I received a response I couldn't process. Could you try rephrasing?\")\n",
    "\n",
    "            print(\"-\" * 28) # Separator\n",
    "\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "             print(\"\\nCafeGenius: Exiting chat.\")\n",
    "             if not current_order.is_empty():\n",
    "                 print(\"\\nFinal Order Summary:\")\n",
    "                 display(Markdown(current_order.display()))\n",
    "             break\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"An error occurred in the chat loop: {e}\")\n",
    "            print(f\"\\n🤖 CafeGenius: Oops! Something went wrong: {str(e)}. Please try again or rephrase.\")\n",
    "            # Optional: attempt to restart chat or exit gracefully\n",
    "            #chat = model.start_chat(...) # Potential restart (careful with history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 15. Run/Re-Run to Initiate/Re-Initiate CafeGenius Assistant\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\" or '__file__' not in locals(): # Check if running as script or notebook cell\n",
    "    # Only run the chat if the API key was successfully configured\n",
    "    if 'GOOGLE_API_KEY' in locals() and GOOGLE_API_KEY:\n",
    "         chat_with_cafe_genius()\n",
    "    else:\n",
    "         print(\"Chat cannot start because the Google API Key is missing or invalid.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
